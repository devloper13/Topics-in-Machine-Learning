{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscreteEnvironment(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def step(self,action):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def reset(self):\n",
    "        pass\n",
    "    \n",
    "class DiscreteAgent(ABC):\n",
    "    @abstractmethod\n",
    "    def __init__(self,env):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def update(self):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_action(self,state):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld(DiscreteEnvironment):\n",
    "    def __init__(self,r,c):\n",
    "        self.maxrow = r\n",
    "        self.maxcol = c\n",
    "        self.tot_act = 4\n",
    "        self.actions = [0,1,2,3]\n",
    "        self.vi_list = []\n",
    "        self.pi_list = []\n",
    "        self.reset()  \n",
    "        \n",
    "    def foul_state(self,row,col):\n",
    "        if row < 0 or row >= self.maxrow or col < 0 or col >= self.maxcol:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    def step(self,action):\n",
    "        row_copy = self.navigate_row\n",
    "        col_copy = self.navigate_col\n",
    "        \n",
    "        if self.navigate_row == self.goal_row and self.navigate_col == self.goal_col:\n",
    "            reward = 10\n",
    "            done = True\n",
    "            state = (self.navigate_row,self.navigate_col)\n",
    "        else:\n",
    "            if action == 0:\n",
    "                self.navigate_row -= 1\n",
    "            elif action == 1:\n",
    "                self.navigate_row += 1\n",
    "            elif action == 2:\n",
    "                self.navigate_col -= 1\n",
    "            elif action == 3:\n",
    "                self.navigate_col += 1\n",
    "\n",
    "            if self.foul_state(self.navigate_row,self.navigate_col): \n",
    "                reward = 0\n",
    "                done = True\n",
    "                state = (row_copy,col_copy)\n",
    "                #print(state)\n",
    "            elif self.navigate_row == self.goal_row and self.navigate_col == self.goal_col:\n",
    "                reward = 10\n",
    "                done = True\n",
    "                state = (self.navigate_row,self.navigate_col)\n",
    "            else: \n",
    "                reward = 0\n",
    "                done = False\n",
    "                state = (self.navigate_row,self.navigate_col)\n",
    "        \n",
    "        return state,reward,done\n",
    "    \n",
    "    '''\n",
    "    Used for dynamic programming methods where the start state is selected iteratively\n",
    "    '''\n",
    "    def set_start_state(self,state):\n",
    "        self.navigate_row = state[0]\n",
    "        self.navigate_col = state[1]\n",
    "        \n",
    "    '''\n",
    "    Initialize random start and goal state\n",
    "    '''\n",
    "    def reset(self):\n",
    "        \n",
    "        #self.start_row = 0#random.randint(0,self.maxrow-1)\n",
    "        #self.start_col = 0#random.randint(0,self.maxcol-1)\n",
    "        self.goal_row = 7#random.randint(0,self.maxrow-1)\n",
    "        self.goal_col = 7#random.randint(0,self.maxcol-1)\n",
    "        #self.navigate_row = self.start_row\n",
    "        #self.navigate_col = self.start_col \n",
    "    \n",
    "    '''\n",
    "    Under construction\n",
    "    '''\n",
    "    def vi_test(self,Q):\n",
    "        N = 10\n",
    "        return_val = 0\n",
    "        while N:\n",
    "            start_row = 0#random.randint(0,self.maxrow-1)\n",
    "            start_col = 0#random.randint(0,self.maxcol-1)\n",
    "            tot_iter = 20\n",
    "            while tot_iter:\n",
    "                state = (start_row,start_col)\n",
    "                self.set_start_state(state)\n",
    "                action = np.argmax(Q[state])\n",
    "                new_state,reward,done = self.step(action)\n",
    "                return_val += (reward + 0.9 * np.max(Q[new_state]))/N\n",
    "                if new_state[0] == self.goal_row and new_state[1] == self.goal_col:\n",
    "                    break\n",
    "                tot_iter -= 1\n",
    "                start_row = new_state[0]\n",
    "                state_col = new_state[1]\n",
    "            N-=1\n",
    "        self.vi_list.append(return_val)\n",
    "    \n",
    "    def pi_test(self,P,V):\n",
    "        N = 10\n",
    "        return_val = 0\n",
    "        while N:\n",
    "            start_row = 0#random.randint(0,self.maxrow-1)\n",
    "            start_col = 0#random.randint(0,self.maxcol-1)\n",
    "            tot_iter = 20\n",
    "            while tot_iter:\n",
    "                state = (start_row,start_col)\n",
    "                self.set_start_state(state)\n",
    "                action = P[state]\n",
    "                new_state,reward,done = self.step(action)\n",
    "                return_val += (reward + 0.9 * V[new_state])/N\n",
    "                if new_state[0] == self.goal_row and new_state[1] == self.goal_col:\n",
    "                    break\n",
    "                tot_iter -= 1\n",
    "                start_row = new_state[0]\n",
    "                state_col = new_state[1]\n",
    "            N-=1\n",
    "        self.pi_list.append(return_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueIteration(DiscreteAgent):\n",
    "    def __init__(self,env):\n",
    "        self.env = env\n",
    "        self.gamma = 0.9\n",
    "        self.Q = np.zeros((env.maxrow,env.maxcol,env.tot_act))\n",
    "        self.V = np.zeros((env.maxrow,env.maxcol))\n",
    "        \n",
    "    def update(self):\n",
    "        for row in range(len(self.V)):\n",
    "            for col in range(len(self.V[row])):\n",
    "                state=(row,col)\n",
    "                for action in self.env.actions:\n",
    "                    self.env.set_start_state(state)\n",
    "                    new_state,reward,done = self.env.step(action)\n",
    "                    #print(reward)\n",
    "                    self.Q[state][action] = reward + self.gamma * self.V[new_state]\n",
    "                self.V[state] = np.max(self.Q[state])\n",
    "        \n",
    "        #print(self.V)\n",
    "        self.env.vi_test(self.Q)\n",
    "    \n",
    "    def get_action(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyIteration(DiscreteAgent):\n",
    "    def __init__(self,env):\n",
    "        self.env = env\n",
    "        self.gamma = 0.9\n",
    "        self.Q = np.zeros((env.maxrow,env.maxcol,env.tot_act))\n",
    "        self.V = np.zeros((env.maxrow,env.maxcol))\n",
    "        self.policy = np.random.randint(env.tot_act,size=(env.maxrow,env.maxcol))\n",
    "        self.policy_stable = False\n",
    "    \n",
    "    def update(self):\n",
    "        while not self.policy_stable:\n",
    "            self.policy_evaluation()\n",
    "            self.policy_improvement()\n",
    "    \n",
    "    def policy_evaluation(self):\n",
    "        eps = 1e-2\n",
    "        while True:\n",
    "            delta = 0\n",
    "            for row in range(len(self.V)):\n",
    "                for col in range(len(self.V[row])):\n",
    "                    state=(row,col)\n",
    "                    v = self.V[state]\n",
    "                    self.env.set_start_state(state)\n",
    "                    action = self.policy[state]\n",
    "                    new_state,reward,done = self.env.step(action)\n",
    "                    self.Q[state][action] = reward + \\\n",
    "                                            self.gamma * self.V[new_state]\n",
    "                    self.V[state] = self.Q[state][action]\n",
    "                    delta = max(delta,np.abs(v-self.V[state]))\n",
    "            #self.env.pi_test(self.policy,self.V)       \n",
    "            #print(self.V)\n",
    "            if delta < eps:\n",
    "                break\n",
    "            \n",
    "    def policy_improvement(self):\n",
    "        self.policy_stable = True\n",
    "        for row in range(len(self.V)):\n",
    "            for col in range(len(self.V[row])):\n",
    "                state=(row,col)\n",
    "                v = self.V[state]\n",
    "                for action in self.env.actions:\n",
    "                    self.env.set_start_state(state)\n",
    "                    new_state,reward,done = self.env.step(action)\n",
    "                    self.Q[state][action] = reward + self.gamma * self.V[new_state]\n",
    "                #if v != np.max(self.Q[state]):\n",
    "                self.V[state] = np.max(self.Q[state])\n",
    "                \n",
    "                if np.argmax(self.Q[state]) != self.policy[state]:\n",
    "                    self.policy[state] = np.argmax(self.Q[state])\n",
    "                    self.policy_stable = False\n",
    "        #print(self.V)\n",
    "        self.env.pi_test(self.policy,self.V)\n",
    "                    \n",
    "    \n",
    "    def get_action(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GridWorld(8,8)\n",
    "agent  = ValueIteration(env)\n",
    "\n",
    "\n",
    "sweep_no,max_sweeps = 0,50\n",
    "while sweep_no < max_sweeps:\n",
    "    #print('new_update')\n",
    "    agent.update()\n",
    "    sweep_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[24.90328076, 27.72757613, 30.86568209, 34.35246649, 38.22667138,\n",
       "        42.53134348, 47.31431248, 52.62872248],\n",
       "       [27.72757613, 30.86568209, 34.35246649, 38.22667138, 42.53134348,\n",
       "        47.31431248, 52.62872248, 58.53362248],\n",
       "       [30.86568209, 34.35246649, 38.22667138, 42.53134348, 47.31431248,\n",
       "        52.62872248, 58.53362248, 65.09462248],\n",
       "       [34.35246649, 38.22667138, 42.53134348, 47.31431248, 52.62872248,\n",
       "        58.53362248, 65.09462248, 72.38462248],\n",
       "       [38.22667138, 42.53134348, 47.31431248, 52.62872248, 58.53362248,\n",
       "        65.09462248, 72.38462248, 80.48462248],\n",
       "       [42.53134348, 47.31431248, 52.62872248, 58.53362248, 65.09462248,\n",
       "        72.38462248, 80.48462248, 89.48462248],\n",
       "       [47.31431248, 52.62872248, 58.53362248, 65.09462248, 72.38462248,\n",
       "        80.48462248, 89.48462248, 99.48462248],\n",
       "       [52.62872248, 58.53362248, 65.09462248, 72.38462248, 80.48462248,\n",
       "        89.48462248, 99.48462248, 99.48462248]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poilcy Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "env1 = GridWorld(8,8)\n",
    "agent  = PolicyIteration(env1)\n",
    "agent.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1]\n",
      " [3 3 3 3 3 3 3 0]]\n",
      "[[25.41460991 28.23890527 31.37701123 34.86379563 38.73800052 43.04267262\n",
      "  47.82564162 53.14005162]\n",
      " [28.23890527 31.37701123 34.86379563 38.73800052 43.04267262 47.82564162\n",
      "  53.14005162 59.04495162]\n",
      " [31.37701123 34.86379563 38.73800052 43.04267262 47.82564162 53.14005162\n",
      "  59.04495162 65.60595162]\n",
      " [34.86379563 38.73800052 43.04267262 47.82564162 53.14005162 59.04495162\n",
      "  65.60595162 72.89595162]\n",
      " [38.73800052 43.04267262 47.82564162 53.14005162 59.04495162 65.60595162\n",
      "  72.89595162 80.99595162]\n",
      " [43.04267262 47.82564162 53.14005162 59.04495162 65.60595162 72.89595162\n",
      "  80.99595162 89.99595162]\n",
      " [47.82564162 53.14005162 59.04495162 65.60595162 72.89595162 80.99595162\n",
      "  89.99595162 99.99595162]\n",
      " [53.14005162 59.04495162 65.60595162 72.89595162 80.99595162 89.99595162\n",
      "  99.99595162 99.99595162]]\n"
     ]
    }
   ],
   "source": [
    "print(agent.policy)\n",
    "print(agent.V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f82a9248208>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iteration_vi = list(range(0,max_sweeps))\n",
    "iteration_pi = list(range(0,len(env1.pi_list)))\n",
    "plt.plot(iteration_vi,env.vi_list,label='Value iteration')\n",
    "plt.plot(iteration_pi,env1.pi_list,label = 'Policy iteration')\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"average return per iteration\")\n",
    "plt.title(\"DP methods\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1488.7160839835265,\n",
       " 2754.1712594227324,\n",
       " 2754.2163181756237]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env1.pi_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Rental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarRental:\n",
    "    def __init__(self,max_car_A,max_car_B):\n",
    "        self.tot_act = 11\n",
    "        self.maxrow = max_car_A+1\n",
    "        self.maxcol = max_car_B+1\n",
    "        self.car_A = max_car_A\n",
    "        self.car_B = max_car_B\n",
    "        self.actions = [-5,-4,-3,-2,-1,0,1,2,3,4,5]\n",
    "        self.index_act = {-5:10,-4:9,-3:8,-2:7,-1:6,0:0,1:1,2:2,3:3,4:4,5:5}\n",
    "        #self.gamma = 0.9\n",
    "        #self.sell_reward = 10\n",
    "        #self.transfer_cost = 2\n",
    "        self.pi_list = []\n",
    "        self.P_rental,self.P_return = self.prepare_transition()\n",
    "    \n",
    "    def prepare_transition(self):\n",
    "        P_rental = np.zeros((self.maxrow,self.maxcol))\n",
    "        P_return = np.zeros((self.maxrow,self.maxcol))\n",
    "        for i in range(0,self.maxrow): #request\n",
    "            for j in range(0,self.maxrow): #return\n",
    "                P_rental[i][j] = self.req_ret(3,i) * self.req_ret(4,j)\n",
    "                P_return[i][j] = self.req_ret(3,i) * self.req_ret(2,j)\n",
    "        return P_rental,P_return\n",
    "            \n",
    "                \n",
    "    def req_ret(self,lamb,N):\n",
    "        return poisson.pmf(N, lamb)\n",
    "    \n",
    "    def pi_test(self,P,V):\n",
    "        N = 10\n",
    "        return_val = 0\n",
    "        while N:\n",
    "            start_row = 0#random.randint(0,self.maxrow-1)\n",
    "            start_col = 0#random.randint(0,self.maxcol-1)\n",
    "            tot_iter = 20\n",
    "            while tot_iter:\n",
    "                state = (start_row,start_col)\n",
    "                self.set_start_state(state)\n",
    "                action = P[state]\n",
    "                new_state,reward,done = self.step(action)\n",
    "                return_val += (reward + 0.9 * V[new_state])/N\n",
    "                if new_state[0] == self.goal_row and new_state[1] == self.goal_col:\n",
    "                    break\n",
    "                tot_iter -= 1\n",
    "                start_row = new_state[0]\n",
    "                state_col = new_state[1]\n",
    "            N-=1\n",
    "        self.pi_list.append(return_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyIterationRental:\n",
    "    def __init__(self,env):\n",
    "        self.env = env\n",
    "        self.gamma = 0.9\n",
    "        self.Q = np.zeros((env.maxrow,env.maxcol,env.tot_act))\n",
    "        self.V = np.zeros((env.maxrow,env.maxcol))\n",
    "        #self.policy = np.random.randint(-5,6,size=(env.maxrow,env.maxcol))\n",
    "        self.policy = np.zeros((env.maxrow,env.maxcol))\n",
    "        self.policy_stable = False\n",
    "    \n",
    "    def update(self):\n",
    "        while not self.policy_stable:\n",
    "            self.policy_evaluation()\n",
    "            self.policy_improvement()\n",
    "    \n",
    "    def policy_evaluation(self):\n",
    "        print(\"Evaluation\")\n",
    "        eps = 1e-2\n",
    "        iterations = 5\n",
    "        while iterations:\n",
    "        #while True:\n",
    "            delta = 0\n",
    "            for row in range(1,len(self.V)):\n",
    "                for col in range(1,len(self.V[row])):\n",
    "                    state=(row,col)\n",
    "                    v = self.V[state]\n",
    "                    #env.set_start_state(state)\n",
    "                    action = int(self.policy[state])\n",
    "                    self.Q[state][action] = self.calculate_return(action,state)\n",
    "                    self.V[state] = self.Q[state][action]\n",
    "                    delta = max(delta,np.abs(v-self.V[state]))\n",
    "            #self.env.pi_test(self.policy,self.V)       \n",
    "            #print(self.V)\n",
    "            iterations-=1\n",
    "            if delta < eps:\n",
    "                break\n",
    "            \n",
    "    def calculate_return(self,action,present_state):\n",
    "        action_cost = 2 * abs(action)\n",
    "        total_return = 0\n",
    "        for rental_A in range(len(self.env.P_rental)):\n",
    "            for rental_B in range(len(self.env.P_rental[rental_A])):\n",
    "                rental_state=(rental_A,rental_B)\n",
    "                prob_rental = self.env.P_rental[rental_state]\n",
    "                rental_cost = (rental_A + rental_B)*10\n",
    "                \n",
    "                for return_A in range(len(self.env.P_return)):\n",
    "                    new_state_A = present_state[0] - rental_A + return_A - action\n",
    "                    if new_state_A > self.env.car_A:\n",
    "                        break\n",
    "                        \n",
    "                    elif new_state_A > 0:\n",
    "                        for return_B in range(len(self.env.P_return[return_A])):\n",
    "                            return_state = (return_A,return_B)\n",
    "                            prob_return = self.env.P_return[return_state]\n",
    "\n",
    "                            new_state_B = present_state[1] - rental_B + return_B + action\n",
    "\n",
    "                            #print((new_state_A,new_state_B))\n",
    "\n",
    "                            if new_state_B > self.env.car_B:\n",
    "                                break\n",
    "                            elif new_state_B > 0:\n",
    "                                total_return+= prob_rental * prob_return * (rental_cost + \\\n",
    "                                               self.gamma * self.V[(new_state_A,new_state_B)]) \n",
    "        \n",
    "        return (total_return - action_cost)\n",
    "                 \n",
    "                \n",
    "    def policy_improvement(self):\n",
    "        print(\"Improvement\")\n",
    "        self.policy_stable = True\n",
    "        for row in range(1,len(self.V)):\n",
    "            for col in range(1,len(self.V[row])):\n",
    "                state=(row,col)\n",
    "                v = self.V[state]\n",
    "                for action in self.env.actions:\n",
    "                    self.Q[state][action] = self.calculate_return(action,state)\n",
    "                #if v != np.max(self.Q[state]):\n",
    "                self.V[state] = np.max(self.Q[state])\n",
    "                \n",
    "                if np.argmax(self.Q[state]) != self.policy[state]:\n",
    "                    self.policy[state] = np.argmax(self.Q[state])\n",
    "                    self.policy_stable = False\n",
    "        #print(self.V)\n",
    "        #self.env.pi_test(self.policy,self.V)\n",
    "                    \n",
    "    \n",
    "    def get_action(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation\n",
      "Improvement\n",
      "Evaluation\n",
      "Improvement\n",
      "Evaluation\n",
      "Improvement\n",
      "Evaluation\n",
      "Improvement\n",
      "Evaluation\n",
      "Improvement\n",
      "Evaluation\n",
      "Improvement\n",
      "Evaluation\n",
      "Improvement\n",
      "Evaluation\n",
      "Improvement\n",
      "Evaluation\n",
      "Improvement\n",
      "Evaluation\n",
      "Improvement\n",
      "Evaluation\n",
      "Improvement\n",
      "Evaluation\n",
      "Improvement\n",
      "Evaluation\n",
      "Improvement\n"
     ]
    }
   ],
   "source": [
    "env_rental = CarRental(20,20)\n",
    "agent  = PolicyIterationRental(env_rental)\n",
    "agent.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ],\n",
       "       [  0.        ,  11.27649337,  18.90500256,  27.68255909,\n",
       "         36.49928297,  49.11179855,  61.96580421,  75.16237412,\n",
       "         89.3801602 , 101.78139001, 114.71717419, 127.86091082,\n",
       "        135.68164191, 135.55628892, 128.12924226, 115.54867459,\n",
       "        101.12277285,  88.09951387,  78.41405945,  72.28802261,\n",
       "         68.74525092],\n",
       "       [  0.        ,  17.57450808,  27.15716149,  39.88180888,\n",
       "         52.77178639,  64.72263158,  79.43169491,  93.57633494,\n",
       "        105.84381998, 119.46053955, 131.44750479, 142.35409379,\n",
       "        152.60123052, 154.56410844, 148.31561434, 135.53887636,\n",
       "        119.53429222, 104.04626077,  91.71145825,  83.28363962,\n",
       "         77.97523438],\n",
       "       [  0.        ,  26.12838116,  38.96734928,  53.03467804,\n",
       "         68.87678467,  83.94118817,  96.84477117, 111.14813081,\n",
       "        124.59336993, 135.74622964, 145.70377154, 156.73212063,\n",
       "        167.6043553 , 171.83151126, 167.4600904 , 155.54061317,\n",
       "        138.98934499, 121.68752188, 106.83132458,  95.80324367,\n",
       "         88.43275987],\n",
       "       [  0.        ,  37.66463487,  52.52407423,  68.54988663,\n",
       "         85.18866433, 101.98882433, 116.68421073, 128.55211505,\n",
       "        140.33441941, 151.85057637, 161.74758903, 171.36304201,\n",
       "        181.28965057, 187.80541779, 185.87454145, 175.8833214 ,\n",
       "        160.04612759, 141.95302478, 125.07265456, 111.38730024,\n",
       "        102.27514621],\n",
       "       [  0.        ,  51.44322807,  67.72293152,  85.36641737,\n",
       "        102.45862719, 119.07857824, 134.88003335, 147.03772372,\n",
       "        156.67285164, 166.71656272, 175.63532209, 184.64458268,\n",
       "        194.14761873, 202.78435265, 203.56613773, 196.36237366,\n",
       "        182.54231437, 165.01872146, 147.13068995, 131.24791838,\n",
       "        118.13954567],\n",
       "       [  0.        ,  66.61918748,  84.77972842, 102.255332  ,\n",
       "        120.04504603, 136.27505043, 150.61161928, 164.24568109,\n",
       "        172.16411389, 179.80103239, 188.42043815, 197.23352996,\n",
       "        206.44006633, 216.85791501, 220.2593709 , 216.28440762,\n",
       "        205.55257642, 190.0863738 , 172.68621882, 155.73765707,\n",
       "        140.42478362],\n",
       "       [  0.        ,  83.77701754, 101.69973236, 120.05583803,\n",
       "        136.83301953, 152.40914891, 166.63320138, 178.68050983,\n",
       "        187.56912141, 194.0280931 , 202.84560417, 211.49286864,\n",
       "        220.65803443, 230.11931309, 235.84073198, 235.09881918,\n",
       "        227.99283789, 215.68940818, 200.23781368, 183.70478582,\n",
       "        167.40697545],\n",
       "       [  0.        , 100.89502853, 119.62008523, 137.10275557,\n",
       "        153.61661804, 168.74662817, 181.48276951, 192.72006848,\n",
       "        203.25143186, 209.4608365 , 218.05044038, 226.0342974 ,\n",
       "        234.10150619, 242.04300137, 249.4259238 , 251.3337653 ,\n",
       "        247.65006324, 238.91642113, 226.44299908, 211.78284799,\n",
       "        196.10747654],\n",
       "       [  0.        , 118.6727402 , 136.89660506, 154.02877013,\n",
       "        170.27276435, 184.21758122, 197.8096978 , 209.4808698 ,\n",
       "        219.84561274, 226.00760132, 231.72160094, 239.19387922,\n",
       "        246.58155546, 253.68422902, 259.80494832, 263.25593047,\n",
       "        262.1054566 , 256.58255938, 247.41127058, 235.58697717,\n",
       "        221.96092058],\n",
       "       [  0.        , 136.06498527, 153.38467767, 170.56843762,\n",
       "        185.43007261, 199.80239678, 212.61779063, 223.88808046,\n",
       "        233.93413024, 241.50946259, 246.61992852, 253.87458296,\n",
       "        259.57412146, 264.07947158, 268.46272794, 270.54987848,\n",
       "        270.80358298, 267.45118306, 260.91523072, 251.82961767,\n",
       "        240.76810741],\n",
       "       [  0.        , 151.61382308, 169.87972071, 185.65293677,\n",
       "        200.6171819 , 214.70811512, 227.19617715, 238.19767503,\n",
       "        248.26920775, 257.53259741, 262.50467062, 266.36751647,\n",
       "        271.78045161, 274.66043558, 276.52719903, 276.25902149,\n",
       "        274.19161891, 269.54507182, 264.79399125, 257.98316926,\n",
       "        249.44476609],\n",
       "       [  0.        , 165.99949752, 184.92832301, 200.04705956,\n",
       "        215.09273102, 228.64240815, 240.67447579, 252.08433608,\n",
       "        262.35327375, 270.88254538, 277.58812516, 280.75045561,\n",
       "        282.42154214, 284.85732349, 285.75495829, 284.16020179,\n",
       "        280.04108713, 274.87472841, 267.11256496, 259.40441512,\n",
       "        250.12049335],\n",
       "       [  0.        , 179.71450873, 199.14010669, 214.4165093 ,\n",
       "        228.84654674, 241.85407792, 253.7660545 , 265.06736042,\n",
       "        274.51272621, 282.76826296, 289.38530902, 294.20860344,\n",
       "        296.70488119, 296.75273432, 294.03904756, 289.5933198 ,\n",
       "        286.40425508, 280.96827714, 273.760687  , 264.26375983,\n",
       "        253.09407518],\n",
       "       [  0.        , 192.95434742, 212.79804088, 228.15704186,\n",
       "        242.04514829, 254.42478675, 266.09442119, 276.38183861,\n",
       "        284.91605779, 292.34783833, 297.75092647, 301.43795412,\n",
       "        303.69351   , 304.03586842, 302.80714112, 299.97256195,\n",
       "        294.99364398, 286.6289303 , 275.99739528, 265.40471895,\n",
       "        253.02123466],\n",
       "       [  0.        , 205.71373082, 225.93249429, 241.35749521,\n",
       "        254.62925228, 266.41288842, 277.70176749, 286.71171891,\n",
       "        294.58317976, 300.36084399, 304.56797829, 307.04853894,\n",
       "        308.00917644, 307.75283659, 306.38180095, 303.55663903,\n",
       "        298.2229346 , 291.47290162, 280.20626051, 265.05191321,\n",
       "        250.54134566],\n",
       "       [  0.        , 217.97403938, 238.5134343 , 253.95195722,\n",
       "        266.4350539 , 277.94689939, 287.94766898, 296.09790102,\n",
       "        302.30074731, 307.14190423, 310.26479781, 312.01179345,\n",
       "        312.60034765, 312.05626656, 310.06009176, 306.33911455,\n",
       "        300.85397999, 291.39264124, 281.17390884, 264.60249472,\n",
       "        243.57962384],\n",
       "       [  0.        , 229.58722823, 250.37928679, 265.76633882,\n",
       "        277.36975138, 288.34060904, 296.7443151 , 304.13868334,\n",
       "        309.56360589, 313.37406991, 315.82310874, 317.01137803,\n",
       "        316.86692333, 315.45152056, 312.64826611, 307.57454869,\n",
       "        299.06776842, 289.36371803, 273.3391335 , 257.2786184 ,\n",
       "        232.9846161 ],\n",
       "       [  0.        , 240.44827667, 261.41855242, 276.68472969,\n",
       "        288.00065104, 297.36293425, 305.29488626, 311.19070773,\n",
       "        315.44089165, 318.27519331, 320.04063451, 320.49353509,\n",
       "        319.58003735, 316.97399031, 311.82397881, 305.00111537,\n",
       "        295.03765987, 279.81321112, 263.31328017, 238.56491024,\n",
       "        215.15102796],\n",
       "       [  0.        , 250.10086506, 271.13347094, 286.16523892,\n",
       "        297.06916169, 305.17420002, 311.25244704, 316.43633918,\n",
       "        320.04445067, 322.21981364, 322.9913893 , 322.23428225,\n",
       "        319.5771612 , 314.99029071, 308.88445058, 298.47860519,\n",
       "        284.76120405, 267.49264994, 244.17463781, 219.59201086,\n",
       "        188.48360424],\n",
       "       [  0.        , 257.71178674, 278.64217828, 293.30801577,\n",
       "        303.69725845, 311.22221565, 316.70007891, 320.53147688,\n",
       "        322.8725339 , 323.73096771, 322.97426041, 320.79942556,\n",
       "        317.31585013, 311.02286721, 300.24818059, 288.04540631,\n",
       "        270.11044566, 248.12278302, 222.49650162, 192.60828721,\n",
       "        162.36375506]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [3, 3, 3, 3, 3, 3, 3, 0]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy\n",
    "#np.savetxt('policy_CarRental.out', agent.policy)\n",
    "#np.savetxt('StateValue_CarRental.out', agent.V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gambling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gamble:\n",
    "    def __init__(self):\n",
    "        #self.maxrow = r\n",
    "        self.maxcol = 101\n",
    "        self.tot_act = 51\n",
    "        self.actions = [i for i in range(0,self.tot_act)]\n",
    "        self.vi_list = []\n",
    "        self.p = 0.3\n",
    "        self.P = [self.p,1-self.p]\n",
    "    \n",
    "    '''\n",
    "    Under construction\n",
    "    '''\n",
    "    def vi_test(self,Q):\n",
    "        N = 10\n",
    "        return_val = 0\n",
    "        while N:\n",
    "            start_row = 0#random.randint(0,self.maxrow-1)\n",
    "            start_col = 0#random.randint(0,self.maxcol-1)\n",
    "            tot_iter = 20\n",
    "            while tot_iter:\n",
    "                state = (start_row,start_col)\n",
    "                self.set_start_state(state)\n",
    "                action = np.argmax(Q[state])\n",
    "                new_state,reward,done = self.step(action)\n",
    "                return_val += (reward + 0.9 * np.max(Q[new_state]))/N\n",
    "                if new_state[0] == self.goal_row and new_state[1] == self.goal_col:\n",
    "                    break\n",
    "                tot_iter -= 1\n",
    "                start_row = new_state[0]\n",
    "                state_col = new_state[1]\n",
    "            N-=1\n",
    "        self.vi_list.append(return_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueIterationGamble:\n",
    "    def __init__(self,env):\n",
    "        self.env = env\n",
    "        #self.gamma = 0.9\n",
    "        self.Q = np.zeros((env.maxcol,env.tot_act))\n",
    "        self.V = np.zeros((101,))\n",
    "        \n",
    "    def update(self):\n",
    "        delta = 0\n",
    "        eps = 1e-2\n",
    "        iterations = 100\n",
    "        while iterations:\n",
    "            for state in range(1,len(self.V)-1):\n",
    "                #print(state)\n",
    "                v = self.V[state]\n",
    "                for action in self.env.actions:\n",
    "                    #self.env.set_start_state(state)\n",
    "                    #new_state,reward,done = self.env.step(action)\n",
    "                    #print(reward)\n",
    "                    self.Q[state][action] = self.calculate_reward(action,state)\n",
    "                    if action == min(state,100-state):\n",
    "                        break\n",
    "                self.V[state] = np.max(self.Q[state])\n",
    "                #delta = max(delta,abs(v-self.V[state]))\n",
    "                #print(delta)\n",
    "                #if delta < eps:\n",
    "                #    break\n",
    "            iterations -= 1\n",
    "                \n",
    "\n",
    "        #print(self.V)\n",
    "        #self.env.vi_test(self.Q)\n",
    "    \n",
    "    def calculate_reward(self,action,state):\n",
    "        return_tot = 0\n",
    "        state_prime = [state+action,state-action]\n",
    "        \n",
    "        for i in range(len(state_prime)):\n",
    "            if state_prime[i] == 100:\n",
    "                reward = 1\n",
    "            else:\n",
    "                reward = 0\n",
    "            return_tot += self.env.P[i] * (reward +  self.V[state_prime[i]]) \n",
    "        \n",
    "        return return_tot\n",
    "    \n",
    "    def get_action(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_gamble =  Gamble()\n",
    "agent_gamble = ValueIterationGamble(env_gamble)\n",
    "agent_gamble.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 2.66917018e-04, 8.89723393e-04, 1.92325355e-03,\n",
       "       2.96574464e-03, 4.32158176e-03, 6.41084517e-03, 8.50388325e-03,\n",
       "       9.88581548e-03, 1.18309578e-02, 1.44052725e-02, 1.77664658e-02,\n",
       "       2.13694839e-02, 2.71868419e-02, 2.83462775e-02, 3.00251072e-02,\n",
       "       3.29527183e-02, 3.52816705e-02, 3.94365260e-02, 4.60307893e-02,\n",
       "       4.80175751e-02, 5.16971693e-02, 5.92215525e-02, 6.31880185e-02,\n",
       "       7.12316130e-02, 9.00000000e-02, 9.06228064e-02, 9.20760213e-02,\n",
       "       9.44875916e-02, 9.69200708e-02, 1.00083691e-01, 1.04958639e-01,\n",
       "       1.09842394e-01, 1.13066903e-01, 1.17605568e-01, 1.23612303e-01,\n",
       "       1.31455087e-01, 1.39862129e-01, 1.53435964e-01, 1.56141314e-01,\n",
       "       1.60058584e-01, 1.66889676e-01, 1.72323898e-01, 1.82018561e-01,\n",
       "       1.97405175e-01, 2.02041008e-01, 2.10626728e-01, 2.28183623e-01,\n",
       "       2.37438710e-01, 2.56207097e-01, 3.00000000e-01, 3.00622806e-01,\n",
       "       3.02076021e-01, 3.04487592e-01, 3.06920071e-01, 3.10083691e-01,\n",
       "       3.14958639e-01, 3.19842394e-01, 3.23066903e-01, 3.27605568e-01,\n",
       "       3.33612303e-01, 3.41455087e-01, 3.49862129e-01, 3.63435964e-01,\n",
       "       3.66141314e-01, 3.70058584e-01, 3.76889676e-01, 3.82323898e-01,\n",
       "       3.92018561e-01, 4.07405175e-01, 4.12041008e-01, 4.20626728e-01,\n",
       "       4.38183623e-01, 4.47438710e-01, 4.66207097e-01, 5.10000000e-01,\n",
       "       5.11453215e-01, 5.14844050e-01, 5.20471047e-01, 5.26146832e-01,\n",
       "       5.33528612e-01, 5.44903490e-01, 5.56298920e-01, 5.63822773e-01,\n",
       "       5.74412993e-01, 5.88428706e-01, 6.06728536e-01, 6.26344968e-01,\n",
       "       6.58017250e-01, 6.64329733e-01, 6.73470028e-01, 6.89409244e-01,\n",
       "       7.02089095e-01, 7.24709975e-01, 7.60612075e-01, 7.71429020e-01,\n",
       "       7.91462366e-01, 8.32428453e-01, 8.54023656e-01, 8.97816560e-01,\n",
       "       0.00000000e+00])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_gamble.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration_vi = list(range(0,max_sweeps))\n",
    "plt.plot(iteration_vi,env.vi_list,label='Value iteration')\n",
    "plt.plot(iteration_pi,env1.pi_list,label = 'Policy iteration')\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"average return per iteration\")\n",
    "plt.title(\"DP methods\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
